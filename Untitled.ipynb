{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6946847",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "275ebd36",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 7.04 GiB for an array with shape (1891078041,) and data type int32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 17>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m tfidf_matrix \u001b[38;5;241m=\u001b[39m tfidf_vectorizer\u001b[38;5;241m.\u001b[39mfit_transform(movies_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moverview\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Calculate the cosine similarity between all movies\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m cosine_similarities \u001b[38;5;241m=\u001b[39m \u001b[43mcosine_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtfidf_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtfidf_matrix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Get the movie recommendations for a given movie\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_recommendations\u001b[39m(movie_title):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:1259\u001b[0m, in \u001b[0;36mcosine_similarity\u001b[1;34m(X, Y, dense_output)\u001b[0m\n\u001b[0;32m   1256\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1257\u001b[0m     Y_normalized \u001b[38;5;241m=\u001b[39m normalize(Y, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m-> 1259\u001b[0m K \u001b[38;5;241m=\u001b[39m \u001b[43msafe_sparse_dot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_normalized\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_normalized\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdense_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdense_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1261\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m K\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:153\u001b[0m, in \u001b[0;36msafe_sparse_dot\u001b[1;34m(a, b, dense_output)\u001b[0m\n\u001b[0;32m    151\u001b[0m         ret \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(a, b)\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 153\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    156\u001b[0m     sparse\u001b[38;5;241m.\u001b[39missparse(a)\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39missparse(b)\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m dense_output\n\u001b[0;32m    159\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(ret, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoarray\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    160\u001b[0m ):\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39mtoarray()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\sparse\\base.py:560\u001b[0m, in \u001b[0;36mspmatrix.__matmul__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    557\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m isscalarlike(other):\n\u001b[0;32m    558\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScalar operands are not allowed, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    559\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m instead\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 560\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__mul__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\sparse\\base.py:480\u001b[0m, in \u001b[0;36mspmatrix.__mul__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m!=\u001b[39m other\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m    479\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdimension mismatch\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 480\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mul_sparse_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;66;03m# If it's a list or whatever, treat it like a matrix\u001b[39;00m\n\u001b[0;32m    483\u001b[0m other_a \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masanyarray(other)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\sparse\\compressed.py:518\u001b[0m, in \u001b[0;36m_cs_matrix._mul_sparse_matrix\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    513\u001b[0m idx_dtype \u001b[38;5;241m=\u001b[39m get_index_dtype((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindptr, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices,\n\u001b[0;32m    514\u001b[0m                              other\u001b[38;5;241m.\u001b[39mindptr, other\u001b[38;5;241m.\u001b[39mindices),\n\u001b[0;32m    515\u001b[0m                             maxval\u001b[38;5;241m=\u001b[39mnnz)\n\u001b[0;32m    517\u001b[0m indptr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(major_axis \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, dtype\u001b[38;5;241m=\u001b[39midx_dtype)\n\u001b[1;32m--> 518\u001b[0m indices \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnnz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43midx_dtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    519\u001b[0m data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(nnz, dtype\u001b[38;5;241m=\u001b[39mupcast(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype, other\u001b[38;5;241m.\u001b[39mdtype))\n\u001b[0;32m    521\u001b[0m fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(_sparsetools, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_matmat\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 7.04 GiB for an array with shape (1891078041,) and data type int32"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load the movie dataset, specifying the data type for the \"overview\" column and setting low_memory to False\n",
    "movies_df = pd.read_csv(\"movies_metadata.csv\", dtype={\"overview\": str}, low_memory=False)\n",
    "\n",
    "# Create a TfidfVectorizer object\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Preprocess the movie descriptions\n",
    "movies_df[\"overview\"] = movies_df[\"overview\"].fillna(\"\")  # Handling missing values\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(movies_df[\"overview\"])\n",
    "\n",
    "# Calculate the cosine similarity between all movies\n",
    "cosine_similarities = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "# Get the movie recommendations for a given movie\n",
    "def get_recommendations(movie_title):\n",
    "    \"\"\"Returns a list of movie recommendations for a given movie title.\"\"\"\n",
    "    \n",
    "    # Get the index of the movie in the dataset\n",
    "    movie_index = movies_df[movies_df[\"original_title\"] == movie_title].index[0]\n",
    "    \n",
    "    # Get the cosine similarities for the movie\n",
    "    movie_similarities = cosine_similarities[movie_index, :]\n",
    "    \n",
    "    # Sort the movies by their cosine similarity\n",
    "    sorted_movies = np.argsort(movie_similarities)[::-1]\n",
    "    \n",
    "    # Get the top 10 movie recommendations\n",
    "    recommendations = sorted_movies[1:11]\n",
    "    \n",
    "    return recommendations\n",
    "\n",
    "# Example usage:\n",
    "# Get the movie recommendations for \"Toy Story\"\n",
    "recommendations = get_recommendations(\"Toy Story\")\n",
    "\n",
    "# Print the movie recommendations\n",
    "for movie in recommendations:\n",
    "    print(movies_df[\"original_title\"][movie])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96a91c86",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 4.07 GiB for an array with shape (546860044,) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 21>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m tfidf_matrix \u001b[38;5;241m=\u001b[39m tfidf_vectorizer\u001b[38;5;241m.\u001b[39mfit_transform(movies_subset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moverview\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Calculate the cosine similarity between all movies\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m cosine_similarities \u001b[38;5;241m=\u001b[39m \u001b[43mcosine_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtfidf_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtfidf_matrix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Get the movie recommendations for a given movie\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_recommendations\u001b[39m(movie_title, cosine_similarities, movies_subset):\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;66;03m# Get the index of the movie in the dataset\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:1259\u001b[0m, in \u001b[0;36mcosine_similarity\u001b[1;34m(X, Y, dense_output)\u001b[0m\n\u001b[0;32m   1256\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1257\u001b[0m     Y_normalized \u001b[38;5;241m=\u001b[39m normalize(Y, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m-> 1259\u001b[0m K \u001b[38;5;241m=\u001b[39m \u001b[43msafe_sparse_dot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_normalized\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_normalized\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdense_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdense_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1261\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m K\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:153\u001b[0m, in \u001b[0;36msafe_sparse_dot\u001b[1;34m(a, b, dense_output)\u001b[0m\n\u001b[0;32m    151\u001b[0m         ret \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(a, b)\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 153\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    156\u001b[0m     sparse\u001b[38;5;241m.\u001b[39missparse(a)\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39missparse(b)\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m dense_output\n\u001b[0;32m    159\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(ret, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoarray\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    160\u001b[0m ):\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39mtoarray()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\sparse\\base.py:560\u001b[0m, in \u001b[0;36mspmatrix.__matmul__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    557\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m isscalarlike(other):\n\u001b[0;32m    558\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScalar operands are not allowed, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    559\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m instead\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 560\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__mul__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\sparse\\base.py:480\u001b[0m, in \u001b[0;36mspmatrix.__mul__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m!=\u001b[39m other\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m    479\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdimension mismatch\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 480\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mul_sparse_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;66;03m# If it's a list or whatever, treat it like a matrix\u001b[39;00m\n\u001b[0;32m    483\u001b[0m other_a \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masanyarray(other)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\sparse\\compressed.py:519\u001b[0m, in \u001b[0;36m_cs_matrix._mul_sparse_matrix\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    517\u001b[0m indptr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(major_axis \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, dtype\u001b[38;5;241m=\u001b[39midx_dtype)\n\u001b[0;32m    518\u001b[0m indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(nnz, dtype\u001b[38;5;241m=\u001b[39midx_dtype)\n\u001b[1;32m--> 519\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnnz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mupcast\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    521\u001b[0m fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(_sparsetools, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_matmat\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    522\u001b[0m fn(M, N, np\u001b[38;5;241m.\u001b[39masarray(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindptr, dtype\u001b[38;5;241m=\u001b[39midx_dtype),\n\u001b[0;32m    523\u001b[0m    np\u001b[38;5;241m.\u001b[39masarray(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices, dtype\u001b[38;5;241m=\u001b[39midx_dtype),\n\u001b[0;32m    524\u001b[0m    \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    527\u001b[0m    other\u001b[38;5;241m.\u001b[39mdata,\n\u001b[0;32m    528\u001b[0m    indptr, indices, data)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 4.07 GiB for an array with shape (546860044,) and data type float64"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load the dataset\n",
    "movies_df = pd.read_csv(\"movies_metadata.csv\", dtype={\"overview\": str}, low_memory=False)\n",
    "\n",
    "# Drop rows with missing values in the 'overview' column\n",
    "movies_df.dropna(subset=['overview'], inplace=True)\n",
    "\n",
    "# Subset the dataset to include only the necessary columns\n",
    "movies_subset = movies_df[['original_title', 'overview']]\n",
    "\n",
    "# Initialize the TF-IDF vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "# Fit and transform the 'overview' text into TF-IDF matrix\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(movies_subset['overview'])\n",
    "\n",
    "# Calculate the cosine similarity between all movies\n",
    "cosine_similarities = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "# Get the movie recommendations for a given movie\n",
    "def get_recommendations(movie_title, cosine_similarities, movies_subset):\n",
    "    # Get the index of the movie in the dataset\n",
    "    movie_index = movies_subset[movies_subset['original_title'] == movie_title].index[0]\n",
    "    \n",
    "    # Get the similarity scores for the movie\n",
    "    similarity_scores = cosine_similarities[movie_index]\n",
    "    \n",
    "    # Get the indices of the most similar movies\n",
    "    similar_movie_indices = similarity_scores.argsort()[::-1][1:]\n",
    "    \n",
    "    # Get the titles of the similar movies\n",
    "    similar_movies = movies_subset.loc[similar_movie_indices, 'original_title']\n",
    "    \n",
    "    return similar_movies\n",
    "\n",
    "# Example usage\n",
    "movie_title = \"Toy Story\"\n",
    "recommendations = get_recommendations(movie_title, cosine_similarities, movies_subset)\n",
    "print(recommendations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4578af68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SUVANSH\\AppData\\Local\\Temp\\ipykernel_6964\\456726242.py:7: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  movies_df = pd.read_csv(\"movies_metadata.csv\", dtype={\"overview\": str})\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 14.8 GiB for an array with shape (44512, 44512) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 26>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m svd_matrix \u001b[38;5;241m=\u001b[39m svd\u001b[38;5;241m.\u001b[39mfit_transform(tfidf_matrix)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Calculate the cosine similarity between all movies\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m cosine_similarities \u001b[38;5;241m=\u001b[39m \u001b[43mcosine_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43msvd_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msvd_matrix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Get the movie recommendations for a given movie\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_recommendations\u001b[39m(movie_title, cosine_similarities, movies_subset):\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;66;03m# Get the index of the movie in the dataset\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:1259\u001b[0m, in \u001b[0;36mcosine_similarity\u001b[1;34m(X, Y, dense_output)\u001b[0m\n\u001b[0;32m   1256\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1257\u001b[0m     Y_normalized \u001b[38;5;241m=\u001b[39m normalize(Y, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m-> 1259\u001b[0m K \u001b[38;5;241m=\u001b[39m \u001b[43msafe_sparse_dot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_normalized\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_normalized\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdense_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdense_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1261\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m K\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:153\u001b[0m, in \u001b[0;36msafe_sparse_dot\u001b[1;34m(a, b, dense_output)\u001b[0m\n\u001b[0;32m    151\u001b[0m         ret \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(a, b)\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 153\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    156\u001b[0m     sparse\u001b[38;5;241m.\u001b[39missparse(a)\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39missparse(b)\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m dense_output\n\u001b[0;32m    159\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(ret, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoarray\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    160\u001b[0m ):\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39mtoarray()\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 14.8 GiB for an array with shape (44512, 44512) and data type float64"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# Load the dataset\n",
    "movies_df = pd.read_csv(\"movies_metadata.csv\", dtype={\"overview\": str})\n",
    "\n",
    "# Drop rows with missing values in the 'overview' column\n",
    "movies_df.dropna(subset=['overview'], inplace=True)\n",
    "\n",
    "# Subset the dataset to include only the necessary columns\n",
    "movies_subset = movies_df[['original_title', 'overview']]\n",
    "\n",
    "# Initialize the TF-IDF vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "# Fit and transform the 'overview' text into TF-IDF matrix\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(movies_subset['overview'])\n",
    "\n",
    "# Reduce the dimensionality of the TF-IDF matrix using Truncated SVD\n",
    "svd = TruncatedSVD(n_components=100)\n",
    "svd_matrix = svd.fit_transform(tfidf_matrix)\n",
    "\n",
    "# Calculate the cosine similarity between all movies\n",
    "cosine_similarities = cosine_similarity(svd_matrix, svd_matrix)\n",
    "\n",
    "# Get the movie recommendations for a given movie\n",
    "def get_recommendations(movie_title, cosine_similarities, movies_subset):\n",
    "    # Get the index of the movie in the dataset\n",
    "    movie_index = movies_subset[movies_subset['original_title'] == movie_title].index[0]\n",
    "    \n",
    "    # Get the similarity scores for the movie\n",
    "    similarity_scores = cosine_similarities[movie_index]\n",
    "    \n",
    "    # Get the indices of the most similar movies\n",
    "    similar_movie_indices = similarity_scores.argsort()[::-1][1:]\n",
    "    \n",
    "    # Get the titles of the similar movies\n",
    "    similar_movies = movies_subset.loc[similar_movie_indices, 'original_title']\n",
    "    \n",
    "    return similar_movies\n",
    "\n",
    "# Example usage\n",
    "movie_title = \"Toy Story\"\n",
    "recommendations = get_recommendations(movie_title, cosine_similarities, movies_subset)\n",
    "print(recommendations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c35bb3cc",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 2.04 GiB for an array with shape (546860044,) and data type int32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 19>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m tfidf_matrix \u001b[38;5;241m=\u001b[39m tfidf_vectorizer\u001b[38;5;241m.\u001b[39mfit_transform(movies_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moverview\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Calculate the cosine similarity between all movies\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m cosine_similarities \u001b[38;5;241m=\u001b[39m \u001b[43mcosine_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtfidf_matrix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Get the movie recommendations for a given movie\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_recommendations\u001b[39m(movie_title):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:1259\u001b[0m, in \u001b[0;36mcosine_similarity\u001b[1;34m(X, Y, dense_output)\u001b[0m\n\u001b[0;32m   1256\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1257\u001b[0m     Y_normalized \u001b[38;5;241m=\u001b[39m normalize(Y, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m-> 1259\u001b[0m K \u001b[38;5;241m=\u001b[39m \u001b[43msafe_sparse_dot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_normalized\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_normalized\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdense_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdense_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1261\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m K\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:153\u001b[0m, in \u001b[0;36msafe_sparse_dot\u001b[1;34m(a, b, dense_output)\u001b[0m\n\u001b[0;32m    151\u001b[0m         ret \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(a, b)\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 153\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    156\u001b[0m     sparse\u001b[38;5;241m.\u001b[39missparse(a)\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39missparse(b)\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m dense_output\n\u001b[0;32m    159\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(ret, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoarray\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    160\u001b[0m ):\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39mtoarray()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\sparse\\base.py:560\u001b[0m, in \u001b[0;36mspmatrix.__matmul__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    557\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m isscalarlike(other):\n\u001b[0;32m    558\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScalar operands are not allowed, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    559\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m instead\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 560\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__mul__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\sparse\\base.py:480\u001b[0m, in \u001b[0;36mspmatrix.__mul__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m!=\u001b[39m other\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m    479\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdimension mismatch\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 480\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mul_sparse_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;66;03m# If it's a list or whatever, treat it like a matrix\u001b[39;00m\n\u001b[0;32m    483\u001b[0m other_a \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masanyarray(other)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\sparse\\compressed.py:518\u001b[0m, in \u001b[0;36m_cs_matrix._mul_sparse_matrix\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    513\u001b[0m idx_dtype \u001b[38;5;241m=\u001b[39m get_index_dtype((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindptr, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices,\n\u001b[0;32m    514\u001b[0m                              other\u001b[38;5;241m.\u001b[39mindptr, other\u001b[38;5;241m.\u001b[39mindices),\n\u001b[0;32m    515\u001b[0m                             maxval\u001b[38;5;241m=\u001b[39mnnz)\n\u001b[0;32m    517\u001b[0m indptr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(major_axis \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, dtype\u001b[38;5;241m=\u001b[39midx_dtype)\n\u001b[1;32m--> 518\u001b[0m indices \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnnz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43midx_dtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    519\u001b[0m data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(nnz, dtype\u001b[38;5;241m=\u001b[39mupcast(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype, other\u001b[38;5;241m.\u001b[39mdtype))\n\u001b[0;32m    521\u001b[0m fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(_sparsetools, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_matmat\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 2.04 GiB for an array with shape (546860044,) and data type int32"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load the movie dataset, specifying the data type for the \"overview\" column and setting low_memory to False\n",
    "movies_df = pd.read_csv(\"movies_metadata.csv\", dtype={\"overview\": str}, low_memory=False)\n",
    "\n",
    "# Create a TfidfVectorizer object with stop words\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "# Preprocess the movie descriptions\n",
    "movies_df[\"overview\"] = movies_df[\"overview\"].fillna(\"\")  # Handling missing values\n",
    "\n",
    "# Fit the TfidfVectorizer on the movie overviews\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(movies_df[\"overview\"])\n",
    "\n",
    "# Calculate the cosine similarity between all movies\n",
    "cosine_similarities = cosine_similarity(tfidf_matrix)\n",
    "\n",
    "# Get the movie recommendations for a given movie\n",
    "def get_recommendations(movie_title):\n",
    "    \"\"\"Returns a list of movie recommendations for a given movie title.\"\"\"\n",
    "    # Get the index of the movie in the dataset\n",
    "    movie_index = movies_df[movies_df[\"original_title\"] == movie_title].index[0]\n",
    "    \n",
    "    # Get the cosine similarities for the movie\n",
    "    movie_similarities = cosine_similarities[movie_index]\n",
    "    \n",
    "    # Sort the movies by their cosine similarity\n",
    "    sorted_movies = np.argsort(movie_similarities)[::-1]\n",
    "    \n",
    "    # Get the top 10 movie recommendations (excluding the movie itself)\n",
    "    recommendations = sorted_movies[1:11]\n",
    "    \n",
    "    return recommendations\n",
    "\n",
    "# Example usage:\n",
    "# Get the movie recommendations for \"Toy Story\"\n",
    "recommendations = get_recommendations(\"Toy Story\")\n",
    "\n",
    "# Print the movie recommendations\n",
    "for movie in recommendations:\n",
    "    print(movies_df[\"original_title\"][movie])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a04e08b9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "blocks must be 2-D",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 24>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     29\u001b[0m         cosine_similarities \u001b[38;5;241m=\u001b[39m cosine_similarity(tfidf_matrix)\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 31\u001b[0m         cosine_similarities \u001b[38;5;241m=\u001b[39m \u001b[43mvstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcosine_similarities\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcosine_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtfidf_matrix\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Get the movie recommendations for a given movie\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_recommendations\u001b[39m(movie_title):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\sparse\\construct.py:501\u001b[0m, in \u001b[0;36mvstack\u001b[1;34m(blocks, format, dtype)\u001b[0m\n\u001b[0;32m    470\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvstack\u001b[39m(blocks, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    471\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    472\u001b[0m \u001b[38;5;124;03m    Stack sparse matrices vertically (row wise)\u001b[39;00m\n\u001b[0;32m    473\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    499\u001b[0m \n\u001b[0;32m    500\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbmat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[43mb\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mblocks\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\sparse\\construct.py:550\u001b[0m, in \u001b[0;36mbmat\u001b[1;34m(blocks, format, dtype)\u001b[0m\n\u001b[0;32m    547\u001b[0m blocks \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(blocks, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    549\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m blocks\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m--> 550\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblocks must be 2-D\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    552\u001b[0m M,N \u001b[38;5;241m=\u001b[39m blocks\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m    554\u001b[0m \u001b[38;5;66;03m# check for fast path cases\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: blocks must be 2-D"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.sparse import vstack\n",
    "\n",
    "# Load the movie dataset, specifying the data type for the \"overview\" column and setting low_memory to False\n",
    "movies_df = pd.read_csv(\"movies_metadata.csv\", dtype={\"overview\": str}, low_memory=False)\n",
    "\n",
    "# Create a TfidfVectorizer object with stop words\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "# Preprocess the movie descriptions\n",
    "movies_df[\"overview\"] = movies_df[\"overview\"].fillna(\"\")  # Handling missing values\n",
    "\n",
    "# Initialize an empty cosine similarity matrix\n",
    "num_movies = len(movies_df)\n",
    "cosine_similarities = None\n",
    "\n",
    "# Batch size for memory-efficient computation\n",
    "batch_size = 1000\n",
    "\n",
    "# Calculate the cosine similarity between all movies in batches\n",
    "for i in range(0, num_movies, batch_size):\n",
    "    batch_movies = movies_df[\"overview\"][i:i+batch_size]\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(batch_movies)\n",
    "    \n",
    "    if cosine_similarities is None:\n",
    "        cosine_similarities = cosine_similarity(tfidf_matrix)\n",
    "    else:\n",
    "        cosine_similarities = vstack((cosine_similarities, cosine_similarity(tfidf_matrix)))\n",
    "\n",
    "# Get the movie recommendations for a given movie\n",
    "def get_recommendations(movie_title):\n",
    "    \"\"\"Returns a list of movie recommendations for a given movie title.\"\"\"\n",
    "    # Get the index of the movie in the dataset\n",
    "    movie_index = movies_df[movies_df[\"original_title\"] == movie_title].index[0]\n",
    "    \n",
    "    # Get the cosine similarities for the movie\n",
    "    movie_similarities = cosine_similarities[movie_index]\n",
    "    \n",
    "    # Sort the movies by their cosine similarity\n",
    "    sorted_movies = np.argsort(movie_similarities)[::-1]\n",
    "    \n",
    "    # Get the top 10 movie recommendations (excluding the movie itself)\n",
    "    recommendations = sorted_movies[1:11]\n",
    "    \n",
    "    return recommendations\n",
    "\n",
    "# Example usage:\n",
    "# Get the movie recommendations for \"Toy Story\"\n",
    "recommendations = get_recommendations(\"Toy Story\")\n",
    "\n",
    "# Print the movie recommendations\n",
    "for movie in recommendations:\n",
    "    print(movies_df[\"original_title\"][movie])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "647a2ae6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "blocks must be 2-D",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 24>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     29\u001b[0m         cosine_similarities \u001b[38;5;241m=\u001b[39m cosine_similarity(tfidf_matrix)\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 31\u001b[0m         cosine_similarities \u001b[38;5;241m=\u001b[39m \u001b[43mvstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcosine_similarities\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcosine_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtfidf_matrix\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Get the movie recommendations for a given movie\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_recommendations\u001b[39m(movie_title):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\sparse\\construct.py:501\u001b[0m, in \u001b[0;36mvstack\u001b[1;34m(blocks, format, dtype)\u001b[0m\n\u001b[0;32m    470\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvstack\u001b[39m(blocks, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    471\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    472\u001b[0m \u001b[38;5;124;03m    Stack sparse matrices vertically (row wise)\u001b[39;00m\n\u001b[0;32m    473\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    499\u001b[0m \n\u001b[0;32m    500\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbmat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[43mb\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mblocks\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\sparse\\construct.py:550\u001b[0m, in \u001b[0;36mbmat\u001b[1;34m(blocks, format, dtype)\u001b[0m\n\u001b[0;32m    547\u001b[0m blocks \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(blocks, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    549\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m blocks\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m--> 550\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblocks must be 2-D\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    552\u001b[0m M,N \u001b[38;5;241m=\u001b[39m blocks\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m    554\u001b[0m \u001b[38;5;66;03m# check for fast path cases\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: blocks must be 2-D"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.sparse import vstack\n",
    "\n",
    "# Load the movie dataset, specifying the data type for the \"overview\" column and setting low_memory to False\n",
    "movies_df = pd.read_csv(\"movies_metadata.csv\", dtype={\"overview\": str}, low_memory=False)\n",
    "\n",
    "# Create a TfidfVectorizer object with stop words\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "# Preprocess the movie descriptions\n",
    "movies_df[\"overview\"] = movies_df[\"overview\"].fillna(\"\")  # Handling missing values\n",
    "\n",
    "# Initialize an empty cosine similarity matrix\n",
    "num_movies = len(movies_df)\n",
    "cosine_similarities = None\n",
    "\n",
    "# Batch size for memory-efficient computation\n",
    "batch_size = 1000\n",
    "\n",
    "# Calculate the cosine similarity between all movies in batches\n",
    "for i in range(0, num_movies, batch_size):\n",
    "    batch_movies = movies_df[\"overview\"][i:i+batch_size]\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(batch_movies)\n",
    "    \n",
    "    if cosine_similarities is None:\n",
    "        cosine_similarities = cosine_similarity(tfidf_matrix)\n",
    "    else:\n",
    "        cosine_similarities = vstack((cosine_similarities, cosine_similarity(tfidf_matrix)))\n",
    "\n",
    "# Get the movie recommendations for a given movie\n",
    "def get_recommendations(movie_title):\n",
    "    \"\"\"Returns a list of movie recommendations for a given movie title.\"\"\"\n",
    "    # Get the index of the movie in the dataset\n",
    "    movie_index = movies_df[movies_df[\"original_title\"] == movie_title].index[0]\n",
    "    \n",
    "    # Get the cosine similarities for the movie\n",
    "    movie_similarities = cosine_similarities[movie_index]\n",
    "    \n",
    "    # Sort the movies by their cosine similarity\n",
    "    sorted_movies = np.argsort(movie_similarities)[::-1]\n",
    "    \n",
    "    # Get the top 10 movie recommendations (excluding the movie itself)\n",
    "    recommendations = sorted_movies[1:11]\n",
    "    \n",
    "    return recommendations\n",
    "\n",
    "# Example usage:\n",
    "# Get the movie recommendations for \"Toy Story\"\n",
    "recommendations = get_recommendations(\"Toy Story\")\n",
    "\n",
    "# Print the movie recommendations\n",
    "for movie in recommendations:\n",
    "    print(movies_df[\"original_title\"][movie])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "72590852",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 1000 and the array at index 45 has size 466",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 29>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     26\u001b[0m     cosine_similarities_list\u001b[38;5;241m.\u001b[39mappend(cosine_similarities)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Concatenate the cosine similarity matrices\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m cosine_similarities \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcosine_similarities_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Get the movie recommendations for a given movie\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_recommendations\u001b[39m(movie_title):\n",
      "File \u001b[1;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: all the input array dimensions for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 1000 and the array at index 45 has size 466"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load the movie dataset, specifying the data type for the \"overview\" column and setting low_memory to False\n",
    "movies_df = pd.read_csv(\"movies_metadata.csv\", dtype={\"overview\": str}, low_memory=False)\n",
    "\n",
    "# Create a TfidfVectorizer object with stop words\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "# Preprocess the movie descriptions\n",
    "movies_df[\"overview\"] = movies_df[\"overview\"].fillna(\"\")  # Handling missing values\n",
    "\n",
    "# Initialize an empty list to store cosine similarity matrices\n",
    "cosine_similarities_list = []\n",
    "\n",
    "# Batch size for memory-efficient computation\n",
    "batch_size = 1000\n",
    "\n",
    "# Calculate the cosine similarity between all movies in batches\n",
    "for i in range(0, len(movies_df), batch_size):\n",
    "    batch_movies = movies_df[\"overview\"][i:i+batch_size]\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(batch_movies)\n",
    "    cosine_similarities = cosine_similarity(tfidf_matrix)\n",
    "    cosine_similarities_list.append(cosine_similarities)\n",
    "\n",
    "# Concatenate the cosine similarity matrices\n",
    "cosine_similarities = np.concatenate(cosine_similarities_list, axis=0)\n",
    "\n",
    "# Get the movie recommendations for a given movie\n",
    "def get_recommendations(movie_title):\n",
    "    \"\"\"Returns a list of movie recommendations for a given movie title.\"\"\"\n",
    "    # Get the index of the movie in the dataset\n",
    "    movie_index = movies_df[movies_df[\"original_title\"] == movie_title].index[0]\n",
    "    \n",
    "    # Get the cosine similarities for the movie\n",
    "    movie_similarities = cosine_similarities[movie_index]\n",
    "    \n",
    "    # Sort the movies by their cosine similarity\n",
    "    sorted_movies = np.argsort(movie_similarities)[::-1]\n",
    "    \n",
    "    # Get the top 10 movie recommendations (excluding the movie itself)\n",
    "    recommendations = sorted_movies[1:11]\n",
    "    \n",
    "    return recommendations\n",
    "\n",
    "# Example usage:\n",
    "# Get the movie recommendations for \"Toy Story\"\n",
    "recommendations = get_recommendations(\"Toy Story\")\n",
    "\n",
    "# Print the movie recommendations\n",
    "for movie in recommendations:\n",
    "    print(movies_df[\"original_title\"][movie])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fec235ef",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "empty vocabulary; perhaps the documents only contain stop words",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 30>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Handle the last batch separately\u001b[39;00m\n\u001b[0;32m     29\u001b[0m last_batch_movies \u001b[38;5;241m=\u001b[39m movies_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moverview\u001b[39m\u001b[38;5;124m\"\u001b[39m][i\u001b[38;5;241m+\u001b[39mbatch_size:]\n\u001b[1;32m---> 30\u001b[0m last_batch_tfidf_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mtfidf_vectorizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlast_batch_movies\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m last_batch_cosine_similarities \u001b[38;5;241m=\u001b[39m cosine_similarity(last_batch_tfidf_matrix)\n\u001b[0;32m     32\u001b[0m cosine_similarities_list\u001b[38;5;241m.\u001b[39mappend(last_batch_cosine_similarities)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:2077\u001b[0m, in \u001b[0;36mTfidfVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   2058\u001b[0m \u001b[38;5;124;03m\"\"\"Learn vocabulary and idf, return document-term matrix.\u001b[39;00m\n\u001b[0;32m   2059\u001b[0m \n\u001b[0;32m   2060\u001b[0m \u001b[38;5;124;03mThis is equivalent to fit followed by transform, but more efficiently\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2074\u001b[0m \u001b[38;5;124;03m    Tf-idf-weighted document-term matrix.\u001b[39;00m\n\u001b[0;32m   2075\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2076\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_params()\n\u001b[1;32m-> 2077\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2078\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfidf\u001b[38;5;241m.\u001b[39mfit(X)\n\u001b[0;32m   2079\u001b[0m \u001b[38;5;66;03m# X is already a transformed view of raw_documents so\u001b[39;00m\n\u001b[0;32m   2080\u001b[0m \u001b[38;5;66;03m# we set copy to False\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1330\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1322\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1323\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpper case characters found in\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1324\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m vocabulary while \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlowercase\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1325\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is True. These entries will not\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1326\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m be matched with any documents\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1327\u001b[0m             )\n\u001b[0;32m   1328\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m-> 1330\u001b[0m vocabulary, X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_count_vocab\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfixed_vocabulary_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1332\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbinary:\n\u001b[0;32m   1333\u001b[0m     X\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfill(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1220\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1218\u001b[0m     vocabulary \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(vocabulary)\n\u001b[0;32m   1219\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m vocabulary:\n\u001b[1;32m-> 1220\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1221\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mempty vocabulary; perhaps the documents only contain stop words\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1222\u001b[0m         )\n\u001b[0;32m   1224\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m indptr[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39miinfo(np\u001b[38;5;241m.\u001b[39mint32)\u001b[38;5;241m.\u001b[39mmax:  \u001b[38;5;66;03m# = 2**31 - 1\u001b[39;00m\n\u001b[0;32m   1225\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _IS_32BIT:\n",
      "\u001b[1;31mValueError\u001b[0m: empty vocabulary; perhaps the documents only contain stop words"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load the movie dataset, specifying the data type for the \"overview\" column and setting low_memory to False\n",
    "movies_df = pd.read_csv(\"movies_metadata.csv\", dtype={\"overview\": str}, low_memory=False)\n",
    "\n",
    "# Create a TfidfVectorizer object with stop words\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "# Preprocess the movie descriptions\n",
    "movies_df[\"overview\"] = movies_df[\"overview\"].fillna(\"\")  # Handling missing values\n",
    "\n",
    "# Initialize an empty list to store cosine similarity matrices\n",
    "cosine_similarities_list = []\n",
    "\n",
    "# Batch size for memory-efficient computation\n",
    "batch_size = 1000\n",
    "\n",
    "# Calculate the cosine similarity between all movies in batches\n",
    "for i in range(0, len(movies_df), batch_size):\n",
    "    batch_movies = movies_df[\"overview\"][i:i+batch_size]\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(batch_movies)\n",
    "    cosine_similarities = cosine_similarity(tfidf_matrix)\n",
    "    cosine_similarities_list.append(cosine_similarities)\n",
    "\n",
    "# Handle the last batch separately\n",
    "last_batch_movies = movies_df[\"overview\"][i+batch_size:]\n",
    "last_batch_tfidf_matrix = tfidf_vectorizer.fit_transform(last_batch_movies)\n",
    "last_batch_cosine_similarities = cosine_similarity(last_batch_tfidf_matrix)\n",
    "cosine_similarities_list.append(last_batch_cosine_similarities)\n",
    "\n",
    "# Concatenate the cosine similarity matrices\n",
    "cosine_similarities = np.concatenate(cosine_similarities_list, axis=0)\n",
    "\n",
    "# Get the movie recommendations for a given movie\n",
    "def get_recommendations(movie_title):\n",
    "    \"\"\"Returns a list of movie recommendations for a given movie title.\"\"\"\n",
    "    # Get the index of the movie in the dataset\n",
    "    movie_index = movies_df[movies_df[\"original_title\"] == movie_title].index[0]\n",
    "    \n",
    "    # Get the cosine similarities for the movie\n",
    "    movie_similarities = cosine_similarities[movie_index]\n",
    "    \n",
    "    # Sort the movies by their cosine similarity\n",
    "    sorted_movies = np.argsort(movie_similarities)[::-1]\n",
    "    \n",
    "    # Get the top 10 movie recommendations (excluding the movie itself)\n",
    "    recommendations = sorted_movies[1:11]\n",
    "    \n",
    "    return recommendations\n",
    "\n",
    "# Example usage:\n",
    "# Get the movie recommendations for \"Toy Story\"\n",
    "recommendations = get_recommendations(\"Toy Story\")\n",
    "\n",
    "# Print the movie recommendations\n",
    "for movie in recommendations:\n",
    "    print(movies_df[\"original_title\"][movie])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ac92dd4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 1000 and the array at index 45 has size 466",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 32>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     29\u001b[0m         cosine_similarities_list\u001b[38;5;241m.\u001b[39mappend(cosine_similarities)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Concatenate the cosine similarity matrices\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m cosine_similarities \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcosine_similarities_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# Get the movie recommendations for a given movie\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_recommendations\u001b[39m(movie_title):\n",
      "File \u001b[1;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: all the input array dimensions for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 1000 and the array at index 45 has size 466"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load the movie dataset, specifying the data type for the \"overview\" column and setting low_memory to False\n",
    "movies_df = pd.read_csv(\"movies_metadata.csv\", dtype={\"overview\": str}, low_memory=False)\n",
    "\n",
    "# Create a TfidfVectorizer object with stop words\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "# Preprocess the movie descriptions\n",
    "movies_df[\"overview\"] = movies_df[\"overview\"].fillna(\"\")  # Handling missing values\n",
    "\n",
    "# Initialize an empty list to store cosine similarity matrices\n",
    "cosine_similarities_list = []\n",
    "\n",
    "# Batch size for memory-efficient computation\n",
    "batch_size = 1000\n",
    "\n",
    "# Calculate the cosine similarity between all movies in batches\n",
    "for i in range(0, len(movies_df), batch_size):\n",
    "    batch_movies = movies_df[\"overview\"][i:i+batch_size]\n",
    "    \n",
    "    # Check if the batch has non-empty documents\n",
    "    if not batch_movies.empty:\n",
    "        tfidf_matrix = tfidf_vectorizer.fit_transform(batch_movies)\n",
    "        cosine_similarities = cosine_similarity(tfidf_matrix)\n",
    "        cosine_similarities_list.append(cosine_similarities)\n",
    "\n",
    "# Concatenate the cosine similarity matrices\n",
    "cosine_similarities = np.concatenate(cosine_similarities_list, axis=0)\n",
    "\n",
    "# Get the movie recommendations for a given movie\n",
    "def get_recommendations(movie_title):\n",
    "    \"\"\"Returns a list of movie recommendations for a given movie title.\"\"\"\n",
    "    # Get the index of the movie in the dataset\n",
    "    movie_index = movies_df[movies_df[\"original_title\"] == movie_title].index[0]\n",
    "    \n",
    "    # Get the cosine similarities for the movie\n",
    "    movie_similarities = cosine_similarities[movie_index, :]\n",
    "    \n",
    "    # Sort the movies by their cosine similarity\n",
    "    sorted_movies = np.argsort(movie_similarities)[::-1]\n",
    "    \n",
    "    # Get the top 10 movie recommendations (excluding the movie itself)\n",
    "    recommendations = sorted_movies[1:11]\n",
    "    \n",
    "    return recommendations\n",
    "\n",
    "# Example usage:\n",
    "# Get the movie recommendations for \"Toy Story\"\n",
    "recommendations = get_recommendations(\"Toy Story\")\n",
    "\n",
    "# Print the movie recommendations\n",
    "for movie in recommendations:\n",
    "    print(movies_df[\"original_title\"][movie])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d5245517",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 1000 and the array at index 45 has size 466",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 32>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     29\u001b[0m         cosine_similarities_list\u001b[38;5;241m.\u001b[39mappend(cosine_similarities)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Concatenate the cosine similarity matrices\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m cosine_similarities \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcosine_similarities_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# Get the movie recommendations for a given movie\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_recommendations\u001b[39m(movie_title):\n",
      "File \u001b[1;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: all the input array dimensions for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 1000 and the array at index 45 has size 466"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load the movie dataset, specifying the data type for the \"overview\" column and setting low_memory to False\n",
    "movies_df = pd.read_csv(\"movies_metadata.csv\", dtype={\"overview\": str}, low_memory=False)\n",
    "\n",
    "# Create a TfidfVectorizer object with stop words\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "# Preprocess the movie descriptions\n",
    "movies_df[\"overview\"] = movies_df[\"overview\"].fillna(\"\")  # Handling missing values\n",
    "\n",
    "# Initialize an empty list to store cosine similarity matrices\n",
    "cosine_similarities_list = []\n",
    "\n",
    "# Batch size for memory-efficient computation\n",
    "batch_size = 1000\n",
    "\n",
    "# Calculate the cosine similarity between all movies in batches\n",
    "for i in range(0, len(movies_df), batch_size):\n",
    "    batch_movies = movies_df[\"overview\"][i:i+batch_size]\n",
    "    \n",
    "    # Check if the batch has non-empty documents\n",
    "    if not batch_movies.empty:\n",
    "        tfidf_matrix = tfidf_vectorizer.fit_transform(batch_movies)\n",
    "        cosine_similarities = cosine_similarity(tfidf_matrix)\n",
    "        cosine_similarities_list.append(cosine_similarities)\n",
    "\n",
    "# Concatenate the cosine similarity matrices\n",
    "cosine_similarities = np.concatenate(cosine_similarities_list, axis=0)\n",
    "\n",
    "# Get the movie recommendations for a given movie\n",
    "def get_recommendations(movie_title):\n",
    "    \"\"\"Returns a list of movie recommendations for a given movie title.\"\"\"\n",
    "    # Get the index of the movie in the dataset\n",
    "    movie_index = movies_df[movies_df[\"original_title\"] == movie_title].index[0]\n",
    "    \n",
    "    # Get the cosine similarities for the movie\n",
    "    movie_similarities = cosine_similarities[movie_index]\n",
    "    \n",
    "    # Sort the movies by their cosine similarity\n",
    "    sorted_movies = np.argsort(movie_similarities)[::-1]\n",
    "    \n",
    "    # Get the top 10 movie recommendations (excluding the movie itself)\n",
    "    recommendations = sorted_movies[1:11]\n",
    "    \n",
    "    return recommendations\n",
    "\n",
    "# Example usage:\n",
    "# Get the movie recommendations for \"Toy Story\"\n",
    "recommendations = get_recommendations(\"Toy Story\")\n",
    "\n",
    "# Print the movie recommendations\n",
    "for movie in recommendations:\n",
    "    print(movies_df[\"original_title\"][movie])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8fe72736",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 1000 and the array at index 45 has size 466",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [20]\u001b[0m, in \u001b[0;36m<cell line: 32>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     29\u001b[0m         cosine_similarities_list\u001b[38;5;241m.\u001b[39mappend(cosine_similarities)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Concatenate the cosine similarity matrices\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m cosine_similarities \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcosine_similarities_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# Get the movie recommendations for a given movie\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_recommendations\u001b[39m(movie_title):\n",
      "File \u001b[1;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: all the input array dimensions for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 1000 and the array at index 45 has size 466"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load the movie dataset, specifying the data type for the \"overview\" column and setting low_memory to False\n",
    "movies_df = pd.read_csv(\"movies_metadata.csv\", dtype={\"overview\": str}, low_memory=False)\n",
    "\n",
    "# Create a TfidfVectorizer object with stop words\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "# Preprocess the movie descriptions\n",
    "movies_df[\"overview\"] = movies_df[\"overview\"].fillna(\"\")  # Handling missing values\n",
    "\n",
    "# Initialize an empty list to store cosine similarity matrices\n",
    "cosine_similarities_list = []\n",
    "\n",
    "# Batch size for memory-efficient computation\n",
    "batch_size = 1000\n",
    "\n",
    "# Calculate the cosine similarity between all movies in batches\n",
    "for i in range(0, len(movies_df), batch_size):\n",
    "    batch_movies = movies_df[\"overview\"][i:i+batch_size]\n",
    "    \n",
    "    # Check if the batch has non-empty documents\n",
    "    if not batch_movies.empty:\n",
    "        tfidf_matrix = tfidf_vectorizer.fit_transform(batch_movies)\n",
    "        cosine_similarities = cosine_similarity(tfidf_matrix)\n",
    "        cosine_similarities_list.append(cosine_similarities)\n",
    "\n",
    "# Concatenate the cosine similarity matrices\n",
    "cosine_similarities = np.concatenate(cosine_similarities_list, axis=1)\n",
    "\n",
    "# Get the movie recommendations for a given movie\n",
    "def get_recommendations(movie_title):\n",
    "    \"\"\"Returns a list of movie recommendations for a given movie title.\"\"\"\n",
    "    # Get the index of the movie in the dataset\n",
    "    movie_index = movies_df[movies_df[\"original_title\"] == movie_title].index[0]\n",
    "    \n",
    "    # Get the cosine similarities for the movie\n",
    "    movie_similarities = cosine_similarities[movie_index, :]\n",
    "    \n",
    "    # Sort the movies by their cosine similarity\n",
    "    sorted_movies = np.argsort(movie_similarities)[::-1]\n",
    "    \n",
    "    # Get the top 10 movie recommendations (excluding the movie itself)\n",
    "    recommendations = sorted_movies[1:11]\n",
    "    \n",
    "    return recommendations\n",
    "\n",
    "# Example usage:\n",
    "# Get the movie recommendations for \"Toy Story\"\n",
    "recommendations = get_recommendations(\"Toy Story\")\n",
    "\n",
    "# Print the movie recommendations\n",
    "for movie in recommendations:\n",
    "    print(movies_df[\"original_title\"][movie])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a086a933",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "blocks[:,0] has incompatible row dimensions. Got blocks[45,0].shape[1] == 466, expected 1000.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [21]\u001b[0m, in \u001b[0;36m<cell line: 33>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     30\u001b[0m         cosine_similarities_list\u001b[38;5;241m.\u001b[39mappend(cosine_similarities)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Concatenate the cosine similarity matrices\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m cosine_similarities \u001b[38;5;241m=\u001b[39m \u001b[43mvstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcosine_similarities_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Get the movie recommendations for a given movie\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_recommendations\u001b[39m(movie_title):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\sparse\\construct.py:501\u001b[0m, in \u001b[0;36mvstack\u001b[1;34m(blocks, format, dtype)\u001b[0m\n\u001b[0;32m    470\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvstack\u001b[39m(blocks, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    471\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    472\u001b[0m \u001b[38;5;124;03m    Stack sparse matrices vertically (row wise)\u001b[39;00m\n\u001b[0;32m    473\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    499\u001b[0m \n\u001b[0;32m    500\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbmat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[43mb\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mblocks\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\sparse\\construct.py:598\u001b[0m, in \u001b[0;36mbmat\u001b[1;34m(blocks, format, dtype)\u001b[0m\n\u001b[0;32m    592\u001b[0m             \u001b[38;5;28;01melif\u001b[39;00m bcol_lengths[j] \u001b[38;5;241m!=\u001b[39m A\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]:\n\u001b[0;32m    593\u001b[0m                 msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblocks[:,\u001b[39m\u001b[38;5;132;01m{j}\u001b[39;00m\u001b[38;5;124m] has incompatible row dimensions. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    594\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGot blocks[\u001b[39m\u001b[38;5;132;01m{i}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m{j}\u001b[39;00m\u001b[38;5;124m].shape[1] == \u001b[39m\u001b[38;5;132;01m{got}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    595\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexpected \u001b[39m\u001b[38;5;132;01m{exp}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(i\u001b[38;5;241m=\u001b[39mi, j\u001b[38;5;241m=\u001b[39mj,\n\u001b[0;32m    596\u001b[0m                                                 exp\u001b[38;5;241m=\u001b[39mbcol_lengths[j],\n\u001b[0;32m    597\u001b[0m                                                 got\u001b[38;5;241m=\u001b[39mA\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]))\n\u001b[1;32m--> 598\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m    600\u001b[0m nnz \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(block\u001b[38;5;241m.\u001b[39mnnz \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m blocks[block_mask])\n\u001b[0;32m    601\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: blocks[:,0] has incompatible row dimensions. Got blocks[45,0].shape[1] == 466, expected 1000."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.sparse import vstack\n",
    "\n",
    "# Load the movie dataset, specifying the data type for the \"overview\" column and setting low_memory to False\n",
    "movies_df = pd.read_csv(\"movies_metadata.csv\", dtype={\"overview\": str}, low_memory=False)\n",
    "\n",
    "# Create a TfidfVectorizer object with stop words\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "# Preprocess the movie descriptions\n",
    "movies_df[\"overview\"] = movies_df[\"overview\"].fillna(\"\")  # Handling missing values\n",
    "\n",
    "# Initialize an empty list to store cosine similarity matrices\n",
    "cosine_similarities_list = []\n",
    "\n",
    "# Batch size for memory-efficient computation\n",
    "batch_size = 1000\n",
    "\n",
    "# Calculate the cosine similarity between all movies in batches\n",
    "for i in range(0, len(movies_df), batch_size):\n",
    "    batch_movies = movies_df[\"overview\"][i:i+batch_size]\n",
    "    \n",
    "    # Check if the batch has non-empty documents\n",
    "    if not batch_movies.empty:\n",
    "        tfidf_matrix = tfidf_vectorizer.fit_transform(batch_movies)\n",
    "        cosine_similarities = cosine_similarity(tfidf_matrix)\n",
    "        cosine_similarities_list.append(cosine_similarities)\n",
    "\n",
    "# Concatenate the cosine similarity matrices\n",
    "cosine_similarities = vstack(cosine_similarities_list)\n",
    "\n",
    "# Get the movie recommendations for a given movie\n",
    "def get_recommendations(movie_title):\n",
    "    \"\"\"Returns a list of movie recommendations for a given movie title.\"\"\"\n",
    "    # Get the index of the movie in the dataset\n",
    "    movie_index = movies_df[movies_df[\"original_title\"] == movie_title].index[0]\n",
    "    \n",
    "    # Get the cosine similarities for the movie\n",
    "    movie_similarities = cosine_similarities[movie_index, :]\n",
    "    \n",
    "    # Sort the movies by their cosine similarity\n",
    "    sorted_movies = np.argsort(movie_similarities)[::-1]\n",
    "    \n",
    "    # Get the top 10 movie recommendations (excluding the movie itself)\n",
    "    recommendations = sorted_movies[1:11]\n",
    "    \n",
    "    return recommendations\n",
    "\n",
    "# Example usage:\n",
    "# Get the movie recommendations for \"Toy Story\"\n",
    "recommendations = get_recommendations(\"Toy Story\")\n",
    "\n",
    "# Print the movie recommendations\n",
    "for movie in recommendations:\n",
    "    print(movies_df[\"original_title\"][movie])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1e6c393b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 1000 and the array at index 45 has size 466",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [23]\u001b[0m, in \u001b[0;36m<cell line: 32>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     29\u001b[0m         cosine_similarities_list\u001b[38;5;241m.\u001b[39mappend(cosine_similarities)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Concatenate the cosine similarity matrices\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m cosine_similarities \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcosine_similarities_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# Get the movie recommendations for a given movie\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_recommendations\u001b[39m(movie_title):\n",
      "File \u001b[1;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: all the input array dimensions for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 1000 and the array at index 45 has size 466"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load the movie dataset, specifying the data type for the \"overview\" column and setting low_memory to False\n",
    "movies_df = pd.read_csv(\"movies_metadata.csv\", dtype={\"overview\": str}, low_memory=False)\n",
    "\n",
    "# Create a TfidfVectorizer object with stop words\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "# Preprocess the movie descriptions\n",
    "movies_df[\"overview\"] = movies_df[\"overview\"].fillna(\"\")  # Handling missing values\n",
    "\n",
    "# Initialize an empty list to store cosine similarity matrices\n",
    "cosine_similarities_list = []\n",
    "\n",
    "# Batch size for memory-efficient computation\n",
    "batch_size = 1000\n",
    "\n",
    "# Calculate the cosine similarity between all movies in batches\n",
    "for i in range(0, len(movies_df), batch_size):\n",
    "    batch_movies = movies_df[\"overview\"][i:i+batch_size]\n",
    "    \n",
    "    # Check if the batch has non-empty documents\n",
    "    if not batch_movies.empty:\n",
    "        tfidf_matrix = tfidf_vectorizer.fit_transform(batch_movies)\n",
    "        cosine_similarities = cosine_similarity(tfidf_matrix)\n",
    "        cosine_similarities_list.append(cosine_similarities)\n",
    "\n",
    "# Concatenate the cosine similarity matrices\n",
    "cosine_similarities = np.concatenate(cosine_similarities_list, axis=1)\n",
    "\n",
    "# Get the movie recommendations for a given movie\n",
    "def get_recommendations(movie_title):\n",
    "    \"\"\"Returns a list of movie recommendations for a given movie title.\"\"\"\n",
    "    # Get the index of the movie in the dataset\n",
    "    movie_index = movies_df[movies_df[\"original_title\"] == movie_title].index[0]\n",
    "    \n",
    "    # Get the cosine similarities for the movie\n",
    "    movie_similarities = cosine_similarities[movie_index, :]\n",
    "    \n",
    "    # Sort the movies by their cosine similarity\n",
    "    sorted_movies = np.argsort(movie_similarities)[::-1]\n",
    "    \n",
    "    # Get the top 10 movie recommendations (excluding the movie itself)\n",
    "    recommendations = sorted_movies[1:11]\n",
    "    \n",
    "    return recommendations\n",
    "\n",
    "# Example usage:\n",
    "# Get the movie recommendations for \"Toy Story\"\n",
    "recommendations = get_recommendations(\"Toy Story\")\n",
    "\n",
    "# Print the movie recommendations\n",
    "for movie in recommendations:\n",
    "    print(movies_df[\"original_title\"][movie])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "62a75f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.sparse import vstack\n",
    "\n",
    "# Load the movie dataset, specifying the data type for the \"overview\" column and setting low_memory to False\n",
    "movies_df = pd.read_csv(\"movies_metadata.csv\", dtype={\"overview\": str}, low_memory=False)\n",
    "\n",
    "# Create a TfidfVectorizer object with stop words\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "# Preprocess the movie descriptions\n",
    "movies_df[\"overview\"] = movies_df[\"overview\"].fillna(\"\")  # Handling missing values\n",
    "\n",
    "# Initialize an empty list to store cosine similarity matrices\n",
    "cosine_similarities_list = []\n",
    "\n",
    "# Batch size for memory-efficient computation\n",
    "batch_size = 1000\n",
    "\n",
    "# Calculate the cosine similarity between all movies in batches\n",
    "for i in range(0, len(movies_df), batch_size):\n",
    "    batch_movies = movies_df[\"overview\"][i:i+batch_size]\n",
    "    \n",
    "    # Check if the batch has non-empty documents\n",
    "    if not batch_movies.empty:\n",
    "        tfidf_matrix = tfidf_vectorizer.fit_transform(batch_movies)\n",
    "        cosine_similarities = cosine_similarity(tfidf_matrix)\n",
    "        \n",
    "        # Pad the cosine similarity matrix with zeros to match the maximum number of columns\n",
    "        if cosine_similarities_list:\n",
    "            max_columns = max(cosine_similarities_list, key=lambda x: x.shape[1]).shape[1]\n",
    "        else:\n",
    "            max_columns = 0\n",
    "        \n",
    "        if cosine_similarities.shape[1] < max_columns:\n",
    "            padding = np.zeros((cosine_similarities.shape[0], max_columns - cosine_similarities.shape[1]))\n",
    "            cosine_similarities = np.hstack((cosine_similarities, padding))\n",
    "        \n",
    "        cosine_similarities_list.append(cosine_similarities)\n",
    "\n",
    "# Stack the cosine similarity matrices vertically along the rows\n",
    "cosine_similarities = vstack(cosine_similarities_list, format='csr')\n",
    "\n",
    "# Get the movie recommendations for a given movie\n",
    "def get_recommendations(movie_title):\n",
    "    \"\"\"Returns a list of movie recommendations for a given movie title.\"\"\"\n",
    "    # Get the index of the movie in the dataset\n",
    "    movie_index = movies_df[movies_df[\"original_title\"] == movie_title].index[0]\n",
    "    \n",
    "    # Get the cosine similarities for the movie\n",
    "    movie_similarities = cosine_similarities[movie_index, :]\n",
    "    \n",
    "    # Sort the movies by their cosine similarity\n",
    "    sorted_movies = np.argsort(movie_similarities)[::-1]\n",
    "    \n",
    "    # Get the top 10 movie recommendations (excluding the movie itself)\n",
    "    recommendations = sorted_movies[1:11]\n",
    "    \n",
    "    return recommendations\n",
    "\n",
    "# Example usage:\n",
    "# Get the movie recommendations for \"Toy Story\"\n",
    "recommendations = get_recommendations(\"Toy Story\")\n",
    "\n",
    "# Print the movie recommendations\n",
    "for movie in recommendations:\n",
    "    print(movies_df[\"original_title\"][movie])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "23aff310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rent-a-Kid\n",
      "Circle of Friends\n",
      "Heaven & Earth\n",
      "Nadja\n",
      "The Amazing Panda Adventure\n",
      "The Browning Version\n",
      "Love Affair\n",
      "Guilty as Sin\n",
      "صمت القصور\n",
      "Babe\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.sparse import vstack\n",
    "\n",
    "# Load the movie dataset, specifying the data type for the \"overview\" column and setting low_memory to False\n",
    "movies_df = pd.read_csv(\"movies_metadata.csv\", dtype={\"overview\": str}, low_memory=False)\n",
    "\n",
    "# Create a TfidfVectorizer object with stop words\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "# Preprocess the movie descriptions\n",
    "movies_df[\"overview\"] = movies_df[\"overview\"].fillna(\"\")  # Handling missing values\n",
    "\n",
    "# Initialize an empty list to store cosine similarity matrices\n",
    "cosine_similarities_list = []\n",
    "\n",
    "# Batch size for memory-efficient computation\n",
    "batch_size = 1000\n",
    "\n",
    "# Calculate the cosine similarity between all movies in batches\n",
    "for i in range(0, len(movies_df), batch_size):\n",
    "    batch_movies = movies_df[\"overview\"][i:i+batch_size]\n",
    "    \n",
    "    # Check if the batch has non-empty documents\n",
    "    if not batch_movies.empty:\n",
    "        tfidf_matrix = tfidf_vectorizer.fit_transform(batch_movies)\n",
    "        cosine_similarities = cosine_similarity(tfidf_matrix)\n",
    "        \n",
    "        # Pad the cosine similarity matrix with zeros to match the maximum number of columns\n",
    "        if cosine_similarities_list:\n",
    "            max_columns = max(cosine_similarities_list, key=lambda x: x.shape[1]).shape[1]\n",
    "        else:\n",
    "            max_columns = 0\n",
    "        \n",
    "        if cosine_similarities.shape[1] < max_columns:\n",
    "            padding = np.zeros((cosine_similarities.shape[0], max_columns - cosine_similarities.shape[1]))\n",
    "            cosine_similarities = np.hstack((cosine_similarities, padding))\n",
    "        \n",
    "        cosine_similarities_list.append(cosine_similarities)\n",
    "\n",
    "# Stack the cosine similarity matrices vertically along the rows\n",
    "cosine_similarities = vstack(cosine_similarities_list, format='csr')\n",
    "\n",
    "# Get the movie recommendations for a given movie\n",
    "def get_recommendations(movie_title):\n",
    "    \"\"\"Returns a list of movie recommendations for a given movie title.\"\"\"\n",
    "    # Preprocess the movie title\n",
    "    processed_title = tfidf_vectorizer.transform([movie_title])\n",
    "    \n",
    "    # Get the cosine similarities for the movie title\n",
    "    title_similarities = cosine_similarity(processed_title, tfidf_matrix)[0]\n",
    "    \n",
    "    # Sort the movies by their cosine similarity\n",
    "    sorted_movies = np.argsort(title_similarities)[::-1]\n",
    "    \n",
    "    # Get the top 10 movie recommendations (excluding the movie itself)\n",
    "    recommendations = sorted_movies[1:11]\n",
    "    \n",
    "    return recommendations\n",
    "\n",
    "# Example usage:\n",
    "# Get the movie recommendations for \"Toy Story\"\n",
    "recommendations = get_recommendations(\"Toy Story\")\n",
    "\n",
    "# Print the movie recommendations\n",
    "for movie in recommendations:\n",
    "    print(movies_df[\"original_title\"][movie])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ab386608",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.sparse import vstack\n",
    "\n",
    "# Load the movie dataset, specifying the data type for the \"overview\" and \"genres\" columns\n",
    "movies_df = pd.read_csv(\"movies_metadata.csv\", dtype={\"overview\": str, \"genres\": str}, low_memory=False)\n",
    "\n",
    "# Load the keywords dataset\n",
    "keywords_df = pd.read_csv(\"keywords.csv\", dtype={\"id\": str, \"keywords\": str}, low_memory=False)\n",
    "\n",
    "# Merge the movie dataset with the keywords dataset based on movie ID\n",
    "movies_df = pd.merge(movies_df, keywords_df, on=\"id\", how=\"left\")\n",
    "\n",
    "# Create a TfidfVectorizer object with stop words\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "# Preprocess the movie descriptions\n",
    "movies_df[\"overview\"] = movies_df[\"overview\"].fillna(\"\")  # Handling missing values\n",
    "\n",
    "# Extract genre information\n",
    "movies_df[\"genres\"] = movies_df[\"genres\"].fillna(\"[]\")  # Handling missing values\n",
    "movies_df[\"genres\"] = movies_df[\"genres\"].apply(lambda x: [genre[\"name\"] for genre in eval(x)])\n",
    "\n",
    "# Extract keywords information\n",
    "movies_df[\"keywords\"] = movies_df[\"keywords\"].fillna(\"[]\")  # Handling missing values\n",
    "movies_df[\"keywords\"] = movies_df[\"keywords\"].apply(lambda x: [keyword[\"name\"] for keyword in eval(x)])\n",
    "\n",
    "# Remove movies with missing or invalid genre information\n",
    "movies_df = movies_df[movies_df[\"genres\"].apply(lambda x: len(x) > 0)]\n",
    "\n",
    "# Initialize an empty list to store cosine similarity matrices\n",
    "cosine_similarities_list = []\n",
    "\n",
    "# Batch size for memory-efficient computation\n",
    "batch_size = 1000\n",
    "\n",
    "# Calculate the cosine similarity between all movies in batches\n",
    "for i in range(0, len(movies_df), batch_size):\n",
    "    batch_movies = movies_df[\"overview\"][i:i+batch_size]\n",
    "    \n",
    "    # Check if the batch has non-empty documents\n",
    "    if not batch_movies.empty:\n",
    "        tfidf_matrix = tfidf_vectorizer.fit_transform(batch_movies)\n",
    "        cosine_similarities = cosine_similarity(tfidf_matrix)\n",
    "        \n",
    "        # Pad the cosine similarity matrix with zeros to match the maximum number of columns\n",
    "        if cosine_similarities_list:\n",
    "            max_columns = max(cosine_similarities_list, key=lambda x: x.shape[1]).shape[1]\n",
    "        else:\n",
    "            max_columns = 0\n",
    "        \n",
    "        if cosine_similarities.shape[1] < max_columns:\n",
    "            padding = np.zeros((cosine_similarities.shape[0], max_columns - cosine_similarities.shape[1]))\n",
    "            cosine_similarities = np.hstack((cosine_similarities, padding))\n",
    "        \n",
    "        cosine_similarities_list.append(cosine_similarities)\n",
    "\n",
    "# Stack the cosine similarity matrices vertically along the rows\n",
    "cosine_similarities = vstack(cosine_similarities_list, format='csr')\n",
    "\n",
    "# Get the movie recommendations for a given movie\n",
    "def get_recommendations(movie_title):\n",
    "    \"\"\"Returns a list of movie recommendations for a given movie title.\"\"\"\n",
    "    # Preprocess the movie title\n",
    "    processed_title = tfidf_vectorizer.transform([movie_title])\n",
    "    \n",
    "    # Get the cosine similarities for the movie title\n",
    "    title_similarities = cosine_similarity(processed_title, tfidf_matrix)[0]\n",
    "    \n",
    "    # Sort the movies by their cosine similarity\n",
    "    sorted_movies = np.argsort(title_similarities)[::-1]\n",
    "    \n",
    "    # Filter movies by genre similarity (consider top 50 similar movies)\n",
    "    top_similar_movies = sorted_movies[:50]\n",
    "    movie_genre = movies_df.loc[movies_df[\"original_title\"] == movie_title, \"genres\"].values[0]\n",
    "    \n",
    "    genre_similarities = []\n",
    "    for movie in top_similar_movies:\n",
    "        if isinstance(movies_df.loc[movie, \"genres\"], list):\n",
    "            movie_genre_similarity = len(set(movie_genre) & set(movies_df.loc[movie, \"genres\"])) / max(1, len(set(movie_genre)))\n",
    "            genre_similarities.append(movie_genre_similarity)\n",
    "    \n",
    "    genre_similarities = np.array(genre_similarities)\n",
    "    \n",
    "    # Sort the movies by their genre similarity (descending order)\n",
    "    genre_sorted_movies = top_similar_movies[np.argsort(genre_similarities)][::-1]\n",
    "    \n",
    "    # Filter movies by keyword similarity (consider top 20 similar movies)\n",
    "    top_similar_movies = genre_sorted_movies[:20]\n",
    "    movie_keywords = movies_df.loc[movies_df[\"original_title\"] == movie_title, \"keywords\"].values[0]\n",
    "    \n",
    "    keyword_similarities = []\n",
    "    for movie in top_similar_movies:\n",
    "        if isinstance(movies_df.loc[movie, \"keywords\"], list) and movie_keywords:\n",
    "            movie_keyword_similarity = len(set(movie_keywords) & set(movies_df.loc[movie, \"keywords\"])) / max(1, len(set(movie_keywords)))\n",
    "            keyword_similarities.append(movie_keyword_similarity)\n",
    "    \n",
    "    keyword_similarities = np.array(keyword_similarities)\n",
    "    \n",
    "    # Sort the movies by their keyword similarity (descending order)\n",
    "    keyword_sorted_movies = top_similar_movies[np.argsort(keyword_similarities)][::-1]\n",
    "    \n",
    "    # Get the top 10 movie recommendations (excluding the movie itself)\n",
    "    recommendations = keyword_sorted_movies[1:11]\n",
    "    \n",
    "    return recommendations\n",
    "\n",
    "# Example usage:\n",
    "# Get the movie recommendations for \"Lucy\"\n",
    "recommendations = get_recommendations(\"Lucy\")\n",
    "\n",
    "# Print the movie recommendations\n",
    "for movie in recommendations:\n",
    "    print(movies_df[\"original_title\"][movie])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4697a74b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
